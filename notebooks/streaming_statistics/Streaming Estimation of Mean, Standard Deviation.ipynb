{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Streaming estimation of mean and std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from time import time\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Streaming calculation of mean and standard deviation\n",
    "#### Batch mean and std\n",
    "Suppose we are given a sequence of $T$ numbers: $x_1,x_2,\\ldots,x_T$ and we want to estimate their mean and standard deviation:\n",
    "\n",
    "* $\\hat{\\mu}_T \\doteq \\frac{1}{T} \\sum_{t=1}^T x_t$\n",
    "* $\\hat{\\sigma}_T=\\sqrt{\\sum_{t=1}^T (x_t-\\hat{\\mu}_T)^2}$\n",
    "\n",
    "These estimates converge to the true mean and std as $T$ increases to $\\infty$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Stream computation\n",
    "To perform the estimation calculation given above we need to go twice over the sequence, once to compute $\\hat{\\mu}_T$ and a second time to compute $\\hat{\\sigma}_T$. If we have a fast stream of data this might not be feasible.\n",
    "\n",
    "On the other hand $\\hat{\\mu}_T \\to \\mu$ as $T \\to \\infty$. So we can use the current estimate of $\\mu$ as a proxy for $\\mu$. This allows us to generate a stream of estimates as follows. \n",
    "\n",
    "* We initialize the estimators:$\\hat{\\mu}_0=0, \\hat{\\sigma}_0=0$\n",
    "* For each $t>0$ we get $x_t$ and update the estimators as follows:\n",
    "* $\\hat{\\mu}_t = \\frac{1}{t} x_t + \\frac{t-1}{t} \\hat{\\mu}_{t-1}$\n",
    "* $\\hat{\\sigma}^2_t = \\frac{1}{t} (x_t-\\hat{\\mu}_t)^2+ \\frac{t-1}{t} \\hat{\\sigma}^2_{t-1}$ \n",
    "\n",
    "These estimators will converge to the correct values if the sequence is IID, but the convergence will be slower than that of the batch method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Exponential decay estimators\n",
    "Often, when the sequences are very long, the elements are not IID but might have time varying mean and std.\n",
    "\n",
    "In such cases a natural approach is to let $t$ increase from $0$ to $T$ and then stop increasing it an keep it at $T$. This is  **similar** (but not equal) to a \"windowing\" approach where at time $t$ we consider only the measurements $x_{t-T+1},\\ldots, x_t$. However, windowing requires keeping the last $T$ measurements in memory.\n",
    "\n",
    "In general we define the \"Exponentially decaying estimators\" for a decay rate $\\alpha>0$ (in the case above $\\alpha = \\frac{1}{T}$) as follows:\n",
    "\n",
    "* We initialize the estimators:$\\hat{\\mu}_0=0, \\hat{\\sigma}_0=0$\n",
    "* For each $t>0$ we get $x_t$ and update the estimators as follows:\n",
    "* $\\hat{\\mu}_t = \\alpha x_t + (1-\\alpha) \\hat{\\mu}_{t-1}$,\n",
    "* $\\hat{\\sigma}^2_t = \\alpha (x_t-\\hat{\\mu}_t)^2+ (1-\\alpha) \\hat{\\sigma}^2_{t-1}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### Implementation\n",
    "We now implement these estimators using classes that are a special case fo python **Iterators**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Using the generator pattern (an iterable)\n",
    "class run_aver:\n",
    "    ## Initialize the object\n",
    "    def __init__(self,alpha=0.0):\n",
    "        self.t = 0.0\n",
    "        self.s = 0.0\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def send(self,x):\n",
    "        if self.alpha==0:\n",
    "            self.s=(x + self.t*self.s)/(self.t+1.0)\n",
    "        else:\n",
    "            self.s=self.alpha*x + (1-self.alpha)*self.s                           \n",
    "        self.t+=1.0\n",
    "        residual=x-self.s\n",
    "        return residual\n",
    "    \n",
    "    def get_state(self):\n",
    "        return self.s\n",
    "\n",
    "# compute the variance of a signal with zero mean\n",
    "class run_var(object):\n",
    "    ## Initialize the object\n",
    "    def __init__(self,alpha=0.0):\n",
    "        self.t = 0.0\n",
    "        self.s = 0.0\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def send(self,y):\n",
    "        x=y*y\n",
    "        if self.alpha==0:\n",
    "            self.s=(x + self.t*self.s)/(self.t+1.0)\n",
    "        else:\n",
    "            self.s=self.alpha*x + (1-self.alpha)*self.s                           \n",
    "        self.t+=1.0\n",
    "        residual=y/math.sqrt(self.s)\n",
    "        return residual\n",
    "    \n",
    "    def get_variance(self):\n",
    "        return self.s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## This function takes as input an input sequence and a setting for alpha.\n",
    "## alpha=0 corresponds to taking the regular average.'\n",
    "## It generates a figure with the different estimations and residuals\n",
    "def plot_mean_std(a,alpha=0.0):\n",
    "    sz=len(a)\n",
    "    r1=np.zeros(sz)\n",
    "    aver=np.zeros(sz)\n",
    "    r2=np.zeros(sz)\n",
    "    std=np.zeros(sz)\n",
    "\n",
    "    Av=run_aver(alpha=alpha)\n",
    "    Std=run_var(alpha=0)\n",
    "\n",
    "    for t in range(sz):\n",
    "        r1[t]=Av.send(a[t])\n",
    "        aver[t]=Av.get_state()\n",
    "        r2[t]=Std.send(r1[t])\n",
    "        std[t]=math.sqrt(Std.get_variance())\n",
    "\n",
    "    print 'var(a)=',np.var(a),'var(r1)=',np.var(r1)\n",
    "    plt.figure(num=None, figsize=(10, 8), dpi=80, facecolor='w', edgecolor='k')\n",
    "    plt.plot(a,label='a')\n",
    "    plt.plot(r1,label='residual 1')\n",
    "    plt.plot(aver,linewidth=3.0,label='average')\n",
    "    plt.plot(r2,label='residual 2')\n",
    "    plt.plot(std,linewidth=3.0,label='STD')\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.grid()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Residuals\n",
    "\"Residuals\" are the part of the signal that remains after the part of the signal that is modeled has been removed.\n",
    "\n",
    "In the code above we use two residuals:\n",
    "\n",
    "1. **r1** is the original signal **x** after the estimated mean has been subtracted out. Assuming that the estimate of the mean is accurate, the residual will have a mean of zero.\n",
    "2. **r2** this is the first residual **r1** after it was divided by the std. Assuming the estimates of he mean and std are accurate the residual has mean zero and std 1.\n",
    "\n",
    "This is the basic idea of \"modeling the residuals\". We assume that the data is a sum of \"signal\" - a part that can be modeled, and \"noise\" - a part that cannot be modeled. The usuall assymption about the unmodeled part is that it is \"white noise\" = the elements are assumed to be drawn IID from a normal distribution with mean 0 and std 1.\n",
    "\n",
    "By iteratively modeling the sequence and computing a residual we \"extract\" all of the signal and wha remains is white noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### DSE Class Work\n",
    "Construct two sequences to be the sum of a sinusoidal signal and noise in the following four combinations.\n",
    "\n",
    "Signal:\n",
    "* Use the same signal for both sequences  (have at least 10 iterations/periods/waves in the data)\n",
    "* make one sinusoid have double the wavelength as the other\n",
    "\n",
    "Noise\n",
    "* Use the same noise for both sequences\n",
    "* Use independent noise for both sequence.\n",
    "\n",
    "Create a function, similar to plot_mean_std which computes the (local) correlation coefficient between the two signals.\n",
    "\n",
    "Create plots for the different signal pairs described above."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
